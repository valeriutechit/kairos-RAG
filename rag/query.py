# rag/query.py
import os
from qdrant_client import QdrantClient
from langchain.embeddings import OpenAIEmbeddings
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()  # –ü–æ–¥–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env

QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
COLLECTION_NAME = "kairos_rag"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Qdrant
qdrant = QdrantClient(
    url=QDRANT_URL,
    api_key=QDRANT_API_KEY,
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è embedder –∏ OpenAI LLM
embedder = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
openai = OpenAI(api_key=OPENAI_API_KEY)

def ask_question(query: str, top_k: int = 3) -> str:
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤–æ–ø—Ä–æ—Å –≤ –≤–µ–∫—Ç–æ—Ä
    query_vector = embedder.embed_query(query)

    # –ò—â–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ Qdrant
    hits = qdrant.search(
        collection_name=COLLECTION_NAME,
        query_vector=query_vector,
        limit=top_k,
    )

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
    contexts = [hit.payload["text"] for hit in hits]

    # –§–æ—Ä–º–∏—Ä—É–µ–º prompt
    context_str = "\n---\n".join(contexts)
    prompt = f"""–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ. –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω ‚Äî —Å–∫–∞–∂–∏ —á–µ—Å—Ç–Ω–æ.
    
–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context_str}

–í–æ–ø—Ä–æ—Å:
{query}

–û—Ç–≤–µ—Ç:"""

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º prompt –≤ OpenAI
    completion = openai.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
    )

    return completion.choices[0].message.content.strip()

# –î–ª—è —Ç–µ—Å—Ç–∞ –∏–∑ CLI
if __name__ == "__main__":
    query = input("‚ùì –í–≤–µ–¥–∏ –≤–æ–ø—Ä–æ—Å: ")
    answer = ask_question(query)
    print("\nüí¨ –û—Ç–≤–µ—Ç:\n", answer)
